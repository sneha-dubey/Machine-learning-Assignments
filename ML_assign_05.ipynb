{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What are the key tasks that machine learning entails? What does data pre-processing imply?"
      ],
      "metadata": {
        "id": "GlEUwP67aYbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key tasks that machine learning entails are:\n",
        "1.)Data preprocessing: Cleaning, transforming, and preparing data for machine learning algorithms.\n",
        "\n",
        "2.)Model selection: choosing the appropriate machine learning algorithm to use for a given task.\n",
        "\n",
        "3.)Model Training:feeding data to the chosen model and adjusting its parameters to optimize performance.\n",
        "\n",
        "4.)Model evaluation: measuring the performance of the model on test data to estimate its ability to generalize to new data.\n",
        "\n",
        "5.)Model deployment:integrating the trained model into a larger system or using it to make predictions on new data.\n",
        "\n",
        "Data pre-processing involves cleaning, transforming, and preparing data for use in machine learning. It includes tasks such as removing missing or irrelevant data, scaling or normalizing features, and encoding categorical variables.Pre-processing can help to reduce noise and increase the signal-to-noise ratio in the data, making it easier for the model to learn patterns and make accurate predictions."
      ],
      "metadata": {
        "id": "pRUE6NaUnH3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Describe quantitative and qualitative data in depth. Make a distinction between the two."
      ],
      "metadata": {
        "id": "Jt5HuIXeacTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantitative data and qualitative data are two types of data used in research and data analysis. The main distinction between the two is that quantitative data is numerical and can be measured and analyzed using statistical methods, while qualitative data is non-numerical and is typically analyzed using methods such as content analysis or thematic analysis.\n",
        "\n",
        "Quantitative data can be further divided into discrete and continuous data. Discrete data consists of individual, separate values that cannot be subdivided, such as the number of people in a room, while continuous data is made up of values that can take on any value within a given range, such as the weight of a person.\n",
        "\n",
        "Qualitative data is non-numerical and is typically collected through interviews, focus groups, observations, or written or visual materials. Qualitative data can be categorized into different types, such as textual data, visual data, or audio data. Qualitative data is often used to gain a deeper understanding of people's experiences, perceptions, or attitudes towards a particular topic. It can be analyzed using methods such as content analysis, thematic analysis, or discourse analysis."
      ],
      "metadata": {
        "id": "Q_4Cr7Mjo3SD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a basic data collection that includes some sample records. Have at least one attribute from\n",
        "each of the machine learning data types."
      ],
      "metadata": {
        "id": "6U_yOfvUafsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example of a basic data collection that includes some sample records, with at least one attribute from each of the machine learning data types:\n",
        "\n",
        "ID\tName\tAge\tGender\tHeight (inches)\tIncome ($)\tMarital Status\tFavorite Color\n",
        "1\tJohn Smith\t35\tMale\t72\t60000\t                 Married\t        Blue\n",
        "2\tJane Doe\t28\tFemale\t65\t50000\t                 Single\t          Green\n",
        "3\tBob Johnson\t42\tMale\t68\t75000\t                 Divorced\t        Red\n",
        "4\tSarah Lee\t19\tFemale\t62\t20000\t                 Single\t          Purple\n",
        "5\tAlex Kim\t57\tMale\t70\t90000\t                   Widowed\t        Yellow\n",
        "\n",
        "ID: a discrete numerical quantitative data for unique identifier\n",
        "\n",
        "Name: a textual attribute\n",
        "\n",
        "Age: a continuous numerical quantitative data\n",
        "\n",
        "Gender: a categorical attribute\n",
        "\n",
        "Height(inches): a continuous numerical attribute\n",
        "\n",
        "Income($): a continuous numerical attribute\n",
        "\n",
        "Marital status:a categorical attribute\n",
        "\n",
        "Favorite color: a categorical attribute"
      ],
      "metadata": {
        "id": "vwp3FQ-KqscV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What are the various causes of machine learning data issues? What are the ramifications?"
      ],
      "metadata": {
        "id": "iwC189GpaicP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are various causes of machine learning data issues:\n",
        "\n",
        "a.)Data quality issues: such as missing data, inconsistent data, or noisy data that can affect the performance of machine learning models.\n",
        "\n",
        "b.)Biased data: when the training data used to build machine learning models does not represent the diversity of the real-world data, resulting in biased predictions.\n",
        "\n",
        "c.)Imbalanced data: when the distribution of data across classes or labels is uneven, leading to models that are biased towards the majority class.\n",
        "\n",
        "d.)Overfitting: when a model is too complex and fits the training data too closely, resulting in poor performance on new data.\n",
        "\n",
        "The ramifications of these data issues can be significant, including:\n",
        "\n",
        "a.)Poor model performance\n",
        "\n",
        "b.)Unfair or discriminatory outcomes\n",
        "\n",
        "c.)lack of trust\n",
        "\n",
        "d.)Missed opportunities"
      ],
      "metadata": {
        "id": "YcqVMDLktc49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Demonstrate various approaches to categorical data exploration with appropriate examples."
      ],
      "metadata": {
        "id": "WSIBuEU0amW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several approaches to explore categorical data in machine learning:\n",
        "\n",
        "a.)Frequency tables: It counts the number of occurrences of each category in a categorical variable. It is useful for understanding the distribution of the variable and identifying the most common categories.\n",
        "\n",
        "b.)Bar chart:It is useful for visualizing the distribution of the variable and comparing the frequencies of different categories.\n",
        "\n",
        "c.)Pie charts:It displays the frequency of each category in a categorical variable using slices of a circle.\n",
        "\n",
        "d.)Cross-tabulation tables:It is used to examine the relationship between two categorical variables. It is useful for identifying patterns or associations between categories. \n",
        "\n",
        "e.)Heat maps:It is used to visualize the frequency of categories in two or more categorical variables using colors. It is useful for identifying patterns or associations between categories. "
      ],
      "metadata": {
        "id": "7_AVYnyiwqy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How would the learning activity be affected if certain variables have missing values? Having said\n",
        "that, what can be done about it?"
      ],
      "metadata": {
        "id": "-FDBOIkhaplx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " if certain variables have missing values, the learning activity can be affected in several ways:\n",
        "\n",
        " First, missing values can lead to biased and inaccurate estimates of the model parameters, which can result in poor predictive performance. Second, if the proportion of missing values is large, it can result in a loss of statistical power and reduced model performance. Finally, missing values can also affect the distribution of the data, which can lead to errors in model interpretation and inference.\n",
        "\n",
        "To address missing values, there are several strategies that can be used:\n",
        "\n",
        "a.)Deletion\n",
        "\n",
        "b.)Imputation\n",
        "\n",
        "c.)Model-based imputation\n",
        "\n",
        "d.)Treat missing values as separate categories"
      ],
      "metadata": {
        "id": "xG-pRGUCzdBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Describe the various methods for dealing with missing data values in depth."
      ],
      "metadata": {
        "id": "c3CcevU7asLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several methods for dealing with missing data values:\n",
        "\n",
        "a.)Deletion method:This can be done in two ways:\n",
        "\n",
        "*   Litwise deletion: This involves deleting all observations with missing data. This method is easy to implement but can result in a loss of power and may introduce bias if the missing data are not missing completely at random (MCAR).\n",
        "*  Pairwise deletion: This involves using only the available data for each analysis. This method can be used to retain as many observations as possible, but it can result in different sample sizes for different analyses.\n",
        "\n",
        "b.)Imputation method:There are several methods for dealing with missing data values. \n",
        "\n",
        "*   Mean imputation:This involves filling in missing values with the mean of the non-missing values. \n",
        "*   Regression imputation:This method can produce more accurate estimates than mean imputation but assumes that there is a linear relationship between the variable with missing data and the other variables.\n",
        "\n",
        "*Maximum liklihood imputation:This involves fitting a model to the non-missing values and using the likelihood function to estimate the missing values.\n",
        "\n",
        "*  Multiple imputation:This involves generating multiple imputed datasets, each with a different set of imputed values. The analyses are then performed on each of the imputed datasets, and the results are combined to produce a final estimate.\n",
        "\n",
        "*  Hot deck imputation: This involves filling in missing values with the value from the nearest neighbor in the dataset.\n",
        "\n",
        "c.)Ignoring missing data: This involves ignoring the missing data and analyzing only the available data. "
      ],
      "metadata": {
        "id": "AyYcOipv2qSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What are the various data pre-processing techniques? Explain dimensionality reduction and\n",
        "function selection in a few words."
      ],
      "metadata": {
        "id": "T_w0Lc_ja0_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing is an important step in machine learning that involves preparing data for analysis.\n",
        "\n",
        "a.)Data Cleaning:Identifying and correcting errors, missing values, and inconsistencies in the data.\n",
        "\n",
        "b.)Data integrating:This involves combining data from multiple sources to create a single dataset.\n",
        "\n",
        "c.)Data transforming:This involves converting data into a suitable format for analysis, such as scaling or normalizing data.\n",
        "\n",
        "d.)Data reduction:This involves reducing the size of the dataset by removing irrelevant or redundant features.\n",
        "\n",
        "e.)Data discretization:This involves converting continuous data into categorical data.\n",
        "\n",
        "Dimensionality reduction is a technique used to reduce the number of features in a dataset while retaining the most important information. This is important because datasets with a large number of features can be computationally expensive and can result in overfitting. \n",
        "\n",
        "Function selection involves selecting the most important features or predictors that are relevant to the outcome variable. This is important because including irrelevant features can result in overfitting and reduced model performance. One common method of function selection is forward selection, which involves starting with an empty model and adding features one at a time based on their predictive power."
      ],
      "metadata": {
        "id": "rqi4HYMY77MT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.) i. What is the IQR? What criteria are used to assess it?"
      ],
      "metadata": {
        "id": "9oWL1Dica391"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IQR(Interquartile range) is used in statistics to measure the spread of a dataset. It is calculated as the difference between the upper quartile(75th percentile) and the lower quartile(25th percentile) of the data.\n",
        "\n",
        " The IQR can be used to access potential outliers by using the rule of thumb that any data point that falls more than 1.5 times the IQR below the lower quartile or above the upper quartile is considered a potential outlier."
      ],
      "metadata": {
        "id": "RppG-VCtWLYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.) ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
        "surpass the upper whisker in length? How can box plots be used to identify outliers?"
      ],
      "metadata": {
        "id": "UK3v_S5Ea8vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot is a graphical representation of the five-number summary of a dataset, which includes the minimum value, the first quartile (Q1), the median, the third quartile (Q3), and the maximum value. Box plots provide a visual summary of the distribution of a dataset, including the central tendency, spread, and skewness of the data.\n",
        "\n",
        "When the lower whisker surpasses the upper whisker in length, it means that the lower quartile (Q1) is closer to the minimum value than the upper quartile (Q3) is to the maximum value, indicating that the data is skewed to the left.\n",
        "\n",
        "Box plots can be used to identify outliers by using the rule of thumb that any data point that falls more than 1.5 times the IQR below the lower quartile or above the upper quartile is considered a potential outlier. Outliers are represented as individual points outside the whiskers of the box plot. Box plots can also be used to compare the distribution of two or more datasets by placing multiple boxes side by side on the same plot."
      ],
      "metadata": {
        "id": "BwK0BLuXa79J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Make brief notes on any two of the following:\n",
        "\n",
        "1.) Data collected at regular intervals\n",
        "\n",
        "2.) The gap between the quartiles\n",
        "\n",
        "3.) Use a cross-tab"
      ],
      "metadata": {
        "id": "WRI_51i7bA1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.)1.) Data collected at regular intervals: Data collected at regular intervals can be useful in a variety of fields, including finance, meteorology, and medicine. By collecting data at regular intervals, researchers can track changes over time, identify trends or patterns in the data, and make predictions or forecasts based on past trends."
      ],
      "metadata": {
        "id": "Qz2IDji_iq8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.2.) The gap between the quartiles: The gap between quartiles refers to the difference between the upper quartile (Q3) and the lower quartile (Q1) of a dataset. This gap is also known as the interquartile range (IQR) and is a measure of variability that is used to describe the spread of a dataset."
      ],
      "metadata": {
        "id": "mR3wBh8GjVfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.3.) Use a cross-tab: A cross tabulation, or \"cross tab,\" is a table that displays the frequency distribution of two or more variables, typically using counts or percentages. Cross tabs are useful for exploring the relationships between categorical variables and can be used to identify patterns or trends in the data."
      ],
      "metadata": {
        "id": "6W-ihuIXjbH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.)Make a comparison between:\n",
        "\n",
        "1. Data with nominal and ordinal values\n",
        "\n",
        "2. Histogram and box plot\n",
        "\n",
        "3. The average and median"
      ],
      "metadata": {
        "id": "BK3F-3bPbSaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. 1.)Data with nominal and ordinal values: Data with nominal and ordinal values refers to data that are measured on a nominal or ordinal scale. Nominal data are categorical data that do not have a natural order or ranking, such as gender or favorite color. Ordinal data are categorical data that have a natural order or ranking, such as education level or customer satisfaction ratings."
      ],
      "metadata": {
        "id": "9NlgSQ07nKKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.2.)Histogram and box plot: "
      ],
      "metadata": {
        "id": "oBj6eaiRobSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms are used to display the distribution of a continuous variable by dividing the range of the variable into a set of intervals, or \"bins,\" and counting the number of data points that fall within each bin.\n",
        "\n",
        "Box plots, on the other hand, are used to display the distribution of a continuous variable by dividing the data into quartiles and displaying them in a visual format. The box represents the middle 50% of the data, with the median line dividing the box in half. "
      ],
      "metadata": {
        "id": "x2wwvPXvpFM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.3.) The average and median: Average is calculated by adding up all the values in the data set and dividing by the total number of values.\n",
        "\n",
        "The median, on the other hand, is the value that separates the top 50% of the data from the bottom 50% of the data. To find the median, the data set is first arranged in order from lowest to highest value. If there are an odd number of values, the median is the middle value. If there are an even number of values, the median is the average of the two middle values. "
      ],
      "metadata": {
        "id": "FozHQ5iMpg7_"
      }
    }
  ]
}